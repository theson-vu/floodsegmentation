{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\master\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from encoder import *\n",
    "import torch\n",
    "import math\n",
    "import glob\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate(model1, model2, data_input_1, data_input_2, flag=False):\n",
    "    # Check if encoder output channels are compatible\n",
    "    if model1.encoder._out_channels[1:] != model2.encoder._out_channels[1:] or flag:\n",
    "        print(torch.softmax(model2(data_input_2), dim=1)[:, 1].detach().cpu().shape)\n",
    "        return None, None, pearsonr(\n",
    "            torch.softmax(model1(data_input_1), dim=1)[:, 1].detach().cpu().flatten(),\n",
    "            torch.softmax(model2(data_input_2), dim=1)[:, 1].detach().cpu().flatten()\n",
    "        )\n",
    "\n",
    "    # Forward pass through both encoders\n",
    "    encoder_1 = model1.encoder(data_input_1)\n",
    "    encoder_2 = model2.encoder(data_input_2)\n",
    "\n",
    "    # Lists to store the intermediate outputs of the decoder blocks for both models\n",
    "    decoder_block_outputs1 = []\n",
    "    decoder_block_outputs2 = []\n",
    "\n",
    "    # Hook function to capture outputs from each decoder block of model1\n",
    "    def hook_fn1(module, input, output):\n",
    "        decoder_block_outputs1.append(output)\n",
    "\n",
    "    # Hook function to capture outputs from each decoder block of model2\n",
    "    def hook_fn2(module, input, output):\n",
    "        decoder_block_outputs2.append(output)\n",
    "\n",
    "    # Register hooks for decoder blocks in both models\n",
    "    for block in model1.decoder.blocks:\n",
    "        block.register_forward_hook(hook_fn1)\n",
    "\n",
    "    for block in model2.decoder.blocks:\n",
    "        block.register_forward_hook(hook_fn2)\n",
    "\n",
    "    # Forward pass through the decoders (the hooks will capture the intermediate outputs)\n",
    "    decoder_1 = model1.decoder(*encoder_1)\n",
    "    decoder_2 = model2.decoder(*encoder_2)\n",
    "\n",
    "    # Get predictions\n",
    "    preds1 = torch.softmax(model1(data_input_1), dim=1)[:, 1]\n",
    "    preds2 = torch.softmax(model2(data_input_2), dim=1)[:, 1]\n",
    "\n",
    "    # Encoder correlation\n",
    "    corr_encoder = {}\n",
    "    for i in range(1, len(encoder_1)):\n",
    "        corr_encoder[i] = pearsonr(\n",
    "            encoder_1[i].detach().cpu().numpy().flatten(),\n",
    "            encoder_2[i].detach().cpu().numpy().flatten()\n",
    "        )\n",
    "\n",
    "    # Decoder correlation (using the outputs captured by the hooks)\n",
    "    corr_decoder = {}\n",
    "    for i in range(len(decoder_block_outputs1)):\n",
    "        corr_decoder[i] = pearsonr(\n",
    "            decoder_block_outputs1[i].detach().cpu().numpy().flatten(),\n",
    "            decoder_block_outputs2[i].detach().cpu().numpy().flatten()\n",
    "        )\n",
    "\n",
    "    # Correlation of final predictions\n",
    "    corr_preds = pearsonr(preds1.detach().cpu().flatten(), preds2.detach().cpu().flatten())\n",
    "\n",
    "    return corr_encoder, corr_decoder, corr_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = smp.Unet(\n",
    "            encoder_name=f\"single_encoder_6\",\n",
    "            encoder_weights=None,\n",
    "            classes=2,\n",
    "            decoder_attention_type=\"scse\",\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "\n",
    "model2 = smp.Unet(\n",
    "            encoder_name=f\"single_encoder_12\",\n",
    "            encoder_weights=None,\n",
    "            classes=2,\n",
    "            decoder_attention_type=\"scse\",\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "\n",
    "model3 = smp.Unet(\n",
    "            encoder_name=\"dual_encoder_dft\",\n",
    "            encoder_depth=5,\n",
    "            encoder_weights=None,\n",
    "            classes=2,\n",
    "            decoder_attention_type=\"scse\",\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "\n",
    "model4 = smp.Unet(\n",
    "            encoder_name=\"dual_resnet_encoder\",\n",
    "            encoder_depth=5,\n",
    "            encoder_weights=None,\n",
    "            classes=2,\n",
    "            decoder_attention_type=\"scse\",\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "\n",
    "model5 = smp.Unet(\n",
    "            encoder_name=\"resnet50\",\n",
    "            classes=2,\n",
    "            decoder_attention_type=\"scse\",\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "\n",
    "model6 = smp.Unet(\n",
    "            encoder_name=f\"single_encoder_24\",\n",
    "            encoder_weights=None,\n",
    "            classes=2,\n",
    "            decoder_attention_type=\"scse\",\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "\n",
    "model7 = smp.Unet(\n",
    "            encoder_name=\"dual_encoder_wav\",\n",
    "            encoder_depth=5,\n",
    "            encoder_weights=None,\n",
    "            classes=2,\n",
    "            decoder_attention_type=\"scse\",\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "\n",
    "# Loading data from precomputed dataset\n",
    "path = \"C:/Users/The Son/Desktop/Uni/Berlin/Masterarbeit/Data/model_data/test\"\n",
    "# Data/ms-dataset-chips\\\\95eff095-c3e9-4c12-bfde-1708b7e19bae\\\\s2\\\\S2A_MSIL1C_20170528T050611_N0205_R076_T44NNP_20170528T050606_00960-03063\\\\B12.tif'\n",
    "data = np.load(f\"{path}/1.npz\", allow_pickle=True)\n",
    "data = data[\"arr_0\"][0]\n",
    "X = data[\"image\"]\n",
    "X = torch.tensor(np.expand_dims(X, axis=0))\n",
    "amps = data[\"amplitude\"]\n",
    "phases = data[\"phase\"]\n",
    "wavelets = torch.tensor(np.expand_dims(data[\"wavelet\"], axis=0)).cuda(non_blocking=True).float()\n",
    "X = X.cuda(non_blocking=True).float()\n",
    "ap = torch.tensor(np.expand_dims(np.concatenate([amps, phases], axis=0), axis=0)).cuda(non_blocking=True).float()\n",
    "\n",
    "X_ap = np.concatenate([X.cpu().numpy(), ap.cpu().numpy()], axis=1)  # Concatenate on CPU first\n",
    "X_ap = torch.tensor(X_ap).cuda(non_blocking=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained_models/baseline\\best_iou_35_0.7432.pt at epoch 35\n",
      "Loaded trained_models/dft\\best_iou_3_0.1556.pt at epoch 3\n",
      "Loaded trained_models/baseline_dft\\best_iou_21_0.7525.pt at epoch 21\n",
      "Loaded trained_models/baseline_deep\\best_iou_16_0.7599.pt at epoch 16\n",
      "Loaded trained_models/deep\\best_iou_23_0.5502.pt at epoch 23\n",
      "Loaded trained_models/wavelet\\best_iou_16_0.2671.pt at epoch 16\n",
      "Loaded trained_models/baseline_wavelet\\best_iou_9_0.3761.pt at epoch 9\n"
     ]
    }
   ],
   "source": [
    "# Load model 1\n",
    "model_weights_path_1 = glob.glob(f\"trained_models/baseline/best_iou*\")[0]\n",
    "model1 = model1.cuda()\n",
    "model1.eval()\n",
    "cp = torch.load(model_weights_path_1)\n",
    "model1.load_state_dict(cp[\"model_state_dict\"])\n",
    "print(f\"Loaded {model_weights_path_1} at epoch {cp['epoch_num']}\")\n",
    "\n",
    "# Load model 2\n",
    "model_weights_path_2 = glob.glob(f\"trained_models/dft/best_iou*\")[0]\n",
    "model2 = model2.cuda()\n",
    "model2.eval()\n",
    "cp = torch.load(model_weights_path_2)\n",
    "model2.load_state_dict(cp[\"model_state_dict\"])\n",
    "print(f\"Loaded {model_weights_path_2} at epoch {cp['epoch_num']}\")\n",
    "\n",
    "# Load model 3\n",
    "model_weights_path_3 = glob.glob(f\"trained_models/baseline_dft/best_iou*\")[0]\n",
    "model3 = model3.cuda()\n",
    "model3.eval()\n",
    "cp = torch.load(model_weights_path_3)\n",
    "model3.load_state_dict(cp[\"model_state_dict\"])\n",
    "print(f\"Loaded {model_weights_path_3} at epoch {cp['epoch_num']}\")\n",
    "\n",
    "# Load model 4\n",
    "model_weights_path_4 = glob.glob(f\"trained_models/baseline_deep/best_iou*\")[0]\n",
    "model4 = model4.cuda()\n",
    "model4.eval()\n",
    "cp = torch.load(model_weights_path_4)\n",
    "model4.load_state_dict(cp[\"model_state_dict\"])\n",
    "print(f\"Loaded {model_weights_path_4} at epoch {cp['epoch_num']}\")\n",
    "\n",
    "# Load model 5\n",
    "model_weights_path_5 = glob.glob(f\"trained_models/deep/best_iou*\")[0]\n",
    "model5 = model5.cuda()\n",
    "model5.eval()\n",
    "cp = torch.load(model_weights_path_5)\n",
    "model5.load_state_dict(cp[\"model_state_dict\"])\n",
    "print(f\"Loaded {model_weights_path_5} at epoch {cp['epoch_num']}\")\n",
    "\n",
    "# Load model 6\n",
    "model_weights_path_6 = glob.glob(f\"trained_models/wavelet/best_iou*\")[0]\n",
    "model6 = model6.cuda()\n",
    "model6.eval()\n",
    "cp = torch.load(model_weights_path_6)\n",
    "model6.load_state_dict(cp[\"model_state_dict\"])\n",
    "print(f\"Loaded {model_weights_path_6} at epoch {cp['epoch_num']}\")\n",
    "\n",
    "# Load model 7\n",
    "model_weights_path_7 = glob.glob(f\"trained_models/baseline_wavelet/best_iou*\")[0]\n",
    "model7 = model7.cuda()\n",
    "model7.encoder.wav = wavelets\n",
    "model7.eval()\n",
    "cp = torch.load(model_weights_path_7)\n",
    "model7.load_state_dict(cp[\"model_state_dict\"])\n",
    "print(f\"Loaded {model_weights_path_7} at epoch {cp['epoch_num']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21935b0dfa0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_ap[:, -12:, :, :].cpu().squeeze(0)[4, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 512])\n",
      "model2: None, None, PearsonRResult(statistic=0.37966579213565665, pvalue=0.0)\n",
      "torch.Size([1, 512, 512])\n",
      "model3: None, None, PearsonRResult(statistic=0.32944795314766717, pvalue=0.0)\n",
      "torch.Size([1, 512, 512])\n",
      "model4: None, None, PearsonRResult(statistic=0.6353588703710444, pvalue=0.0)\n",
      "torch.Size([1, 512, 512])\n",
      "model5: None, None, PearsonRResult(statistic=0.7818044252309995, pvalue=0.0)\n",
      "torch.Size([1, 512, 512])\n",
      "model6: None, None, PearsonRResult(statistic=-0.06262492236485173, pvalue=5.1255461456061845e-226)\n",
      "torch.Size([1, 512, 512])\n",
      "model7: None, None, PearsonRResult(statistic=0.402275447354167, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "params = [ap, X_ap, X, X[:, :3, :, :], wavelets, X]\n",
    "i = 2\n",
    "for model, params in zip([model2, model3, model4, model5, model6, model7], params):\n",
    "    corr_enc, corr_dec, corr_pred = correlate(model1, model, X, params, True)\n",
    "    print(f\"model{i}: {corr_enc}, {corr_dec}, {corr_pred}\")\n",
    "    i += 1\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
